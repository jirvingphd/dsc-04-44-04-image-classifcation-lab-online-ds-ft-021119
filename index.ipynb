{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Now that you have a working knowledge of CNNs and have practiced implementing associated techniques in Keras, its time to put all of those skills together. In this lab, you'll work to complete a Kaggle competition on classifying dog breeds.\n",
    "\n",
    "https://www.kaggle.com/c/dog-breed-identification\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "* Independently design and build a CNN for image classifcation tasks\n",
    "* Compare and apply multiple techniques for tuning a model including data augmentation and adapting pretrained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Load the Data\n",
    "\n",
    "Start by downloading the data locally and loading it into a Pandas DataFrame. Be forewarened that this dataset is fairly large and it is advisable to close other memory intensive applications.\n",
    "\n",
    "The data can be found here:\n",
    "\n",
    "https://www.kaggle.com/c/dog-breed-identification/data\n",
    "\n",
    "We recommend downloading the data into this directory on your local computer. From there, be sure to uncompress the folder and subfolders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View our documentation at https://bs-ds.readthedocs.io/en/latest/index.html\n",
      "For convenient loading of standard modules :\n",
      ">> from bs_ds.imports import *\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Module/Package Handle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pandas</th>\n",
       "      <td>pd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numpy</th>\n",
       "      <td>np</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matplotlib</th>\n",
       "      <td>mpl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matplotlib.pyplot</th>\n",
       "      <td>plt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seaborn</th>\n",
       "      <td>sns</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Module/Package Handle\n",
       "pandas                               pd\n",
       "numpy                                np\n",
       "matplotlib                          mpl\n",
       "matplotlib.pyplot                   plt\n",
       "seaborn                             sns"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To disable styled DataFrames run html_off() at the bottom of any cell.\n",
      " To re-enable use html_on() at the bottom of any cell.\n"
     ]
    }
   ],
   "source": [
    "import bs_ds as bs\n",
    "from bs_ds.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No code persay, but download and decompress the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Now that you've downloaded the data, its time to prepare it for some model building! You'll notice that the current structure provided is not the same as our lovely preprocessed folders that we've been providing you. Instead, you have one large training folder with images and a csv file with labels associated with each of these file types. \n",
    "\n",
    "Use this to create a directory substructure for a train-validation-test split as we have done previously. Also recall from our previous work that you'll also want to use one-hot encoding as we are now presented with a multi-class problem as opposed to simple binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here; open the labels.csv file stored in the zip file\n",
    "labels = 'data_raw/labels.csv'\n",
    "df = pd.read_csv(labels)\n",
    "# df.set_index('id',inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10222 entries, 0 to 10221\n",
      "Data columns (total 2 columns):\n",
      "id       10222 non-null object\n",
      "breed    10222 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 159.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wish to create our standard directory structure:\n",
    "* train\n",
    "    * category1\n",
    "    * category2\n",
    "    * category3\n",
    "    ...\n",
    "* val\n",
    "    * category1\n",
    "    * category2\n",
    "    * category3\n",
    "    ...\n",
    "* test \n",
    "    * category1\n",
    "    * category2\n",
    "    * category3\n",
    "    ...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "new_root_dir = \"data_org/\"\n",
    "if os.path.exists(new_root_dir)==0:\n",
    "    os.mkdir(new_root_dir)\n",
    "    \n",
    "    \n",
    "raw_test_dir = \"data_raw/test/\"\n",
    "raw_train_dir = \"data_raw/train/\"  \n",
    "    \n",
    "# Define the directory of images to be used and split as old_dir\n",
    "old_dir = raw_train_dir # specify current directory of training data to be split\n",
    "\n",
    "# Define directories to make in new_root_dir\n",
    "dir_names = ['train', 'val', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving boston_bull pictures.\n",
      "Split 87 imgs into 69 train, 9 val, and 9 test examples.\n",
      "Moving dingo pictures.\n",
      "Split 80 imgs into 64 train, 8 val, and 8 test examples.\n",
      "Moving pekinese pictures.\n",
      "Split 75 imgs into 60 train, 7 val, and 8 test examples.\n",
      "Moving bluetick pictures.\n",
      "Split 85 imgs into 68 train, 8 val, and 9 test examples.\n",
      "Moving golden_retriever pictures.\n",
      "Split 67 imgs into 53 train, 7 val, and 7 test examples.\n",
      "Moving bedlington_terrier pictures.\n",
      "Split 89 imgs into 71 train, 9 val, and 9 test examples.\n",
      "Moving borzoi pictures.\n",
      "Split 75 imgs into 60 train, 7 val, and 8 test examples.\n",
      "Moving basenji pictures.\n",
      "Split 110 imgs into 88 train, 11 val, and 11 test examples.\n",
      "Moving scottish_deerhound pictures.\n",
      "Split 126 imgs into 100 train, 13 val, and 13 test examples.\n",
      "Moving shetland_sheepdog pictures.\n",
      "Split 76 imgs into 60 train, 8 val, and 8 test examples.\n",
      "Moving walker_hound pictures.\n",
      "Split 69 imgs into 55 train, 7 val, and 7 test examples.\n",
      "Moving maltese_dog pictures.\n",
      "Split 117 imgs into 93 train, 12 val, and 12 test examples.\n",
      "Moving norfolk_terrier pictures.\n",
      "Split 83 imgs into 66 train, 8 val, and 9 test examples.\n",
      "Moving african_hunting_dog pictures.\n",
      "Split 86 imgs into 68 train, 9 val, and 9 test examples.\n",
      "Moving wire-haired_fox_terrier pictures.\n",
      "Split 82 imgs into 65 train, 8 val, and 9 test examples.\n",
      "Moving redbone pictures.\n",
      "Split 72 imgs into 57 train, 7 val, and 8 test examples.\n",
      "Moving lakeland_terrier pictures.\n",
      "Split 99 imgs into 79 train, 10 val, and 10 test examples.\n",
      "Moving boxer pictures.\n",
      "Split 75 imgs into 60 train, 7 val, and 8 test examples.\n",
      "Moving doberman pictures.\n",
      "Split 74 imgs into 59 train, 7 val, and 8 test examples.\n",
      "Moving otterhound pictures.\n",
      "Split 69 imgs into 55 train, 7 val, and 7 test examples.\n",
      "Moving standard_schnauzer pictures.\n",
      "Split 72 imgs into 57 train, 7 val, and 8 test examples.\n",
      "Moving irish_water_spaniel pictures.\n",
      "Split 78 imgs into 62 train, 8 val, and 8 test examples.\n",
      "Moving black-and-tan_coonhound pictures.\n",
      "Split 77 imgs into 61 train, 8 val, and 8 test examples.\n",
      "Moving cairn pictures.\n",
      "Split 106 imgs into 84 train, 11 val, and 11 test examples.\n",
      "Moving affenpinscher pictures.\n",
      "Split 80 imgs into 64 train, 8 val, and 8 test examples.\n",
      "Moving labrador_retriever pictures.\n",
      "Split 84 imgs into 67 train, 8 val, and 9 test examples.\n",
      "Moving ibizan_hound pictures.\n",
      "Split 91 imgs into 72 train, 9 val, and 10 test examples.\n",
      "Moving english_setter pictures.\n",
      "Split 83 imgs into 66 train, 8 val, and 9 test examples.\n",
      "Moving weimaraner pictures.\n",
      "Split 85 imgs into 68 train, 8 val, and 9 test examples.\n",
      "Moving giant_schnauzer pictures.\n",
      "Split 69 imgs into 55 train, 7 val, and 7 test examples.\n",
      "Moving groenendael pictures.\n",
      "Split 82 imgs into 65 train, 8 val, and 9 test examples.\n",
      "Moving dhole pictures.\n",
      "Split 76 imgs into 60 train, 8 val, and 8 test examples.\n",
      "Moving toy_poodle pictures.\n",
      "Split 80 imgs into 64 train, 8 val, and 8 test examples.\n",
      "Moving border_terrier pictures.\n",
      "Split 91 imgs into 72 train, 9 val, and 10 test examples.\n",
      "Moving tibetan_terrier pictures.\n",
      "Split 107 imgs into 85 train, 11 val, and 11 test examples.\n",
      "Moving norwegian_elkhound pictures.\n",
      "Split 95 imgs into 76 train, 9 val, and 10 test examples.\n",
      "Moving shih-tzu pictures.\n",
      "Split 112 imgs into 89 train, 11 val, and 12 test examples.\n",
      "Moving irish_terrier pictures.\n",
      "Split 82 imgs into 65 train, 8 val, and 9 test examples.\n",
      "Moving kuvasz pictures.\n",
      "Split 71 imgs into 56 train, 7 val, and 8 test examples.\n",
      "Moving german_shepherd pictures.\n",
      "Split 69 imgs into 55 train, 7 val, and 7 test examples.\n",
      "Moving greater_swiss_mountain_dog pictures.\n",
      "Split 82 imgs into 65 train, 8 val, and 9 test examples.\n",
      "Moving basset pictures.\n",
      "Split 82 imgs into 65 train, 8 val, and 9 test examples.\n",
      "Moving australian_terrier pictures.\n",
      "Split 102 imgs into 81 train, 10 val, and 11 test examples.\n",
      "Moving schipperke pictures.\n",
      "Split 86 imgs into 68 train, 9 val, and 9 test examples.\n",
      "Moving rhodesian_ridgeback pictures.\n",
      "Split 88 imgs into 70 train, 9 val, and 9 test examples.\n",
      "Moving irish_setter pictures.\n",
      "Split 88 imgs into 70 train, 9 val, and 9 test examples.\n",
      "Moving appenzeller pictures.\n",
      "Split 78 imgs into 62 train, 8 val, and 8 test examples.\n",
      "Moving bloodhound pictures.\n",
      "Split 85 imgs into 68 train, 8 val, and 9 test examples.\n",
      "Moving samoyed pictures.\n",
      "Split 109 imgs into 87 train, 11 val, and 11 test examples.\n",
      "Moving miniature_schnauzer pictures.\n",
      "Split 78 imgs into 62 train, 8 val, and 8 test examples.\n",
      "Moving brittany_spaniel pictures.\n",
      "Split 73 imgs into 58 train, 7 val, and 8 test examples.\n",
      "Moving kelpie pictures.\n",
      "Split 86 imgs into 68 train, 9 val, and 9 test examples.\n",
      "Moving papillon pictures.\n",
      "Split 96 imgs into 76 train, 10 val, and 10 test examples.\n",
      "Moving border_collie pictures.\n",
      "Split 72 imgs into 57 train, 7 val, and 8 test examples.\n",
      "Moving entlebucher pictures.\n",
      "Split 115 imgs into 92 train, 11 val, and 12 test examples.\n",
      "Moving collie pictures.\n",
      "Split 87 imgs into 69 train, 9 val, and 9 test examples.\n",
      "Moving malamute pictures.\n",
      "Split 81 imgs into 64 train, 8 val, and 9 test examples.\n",
      "Moving welsh_springer_spaniel pictures.\n",
      "Split 79 imgs into 63 train, 8 val, and 8 test examples.\n",
      "Moving chihuahua pictures.\n",
      "Split 71 imgs into 56 train, 7 val, and 8 test examples.\n",
      "Moving saluki pictures.\n",
      "Split 99 imgs into 79 train, 10 val, and 10 test examples.\n",
      "Moving pug pictures.\n",
      "Split 94 imgs into 75 train, 9 val, and 10 test examples.\n",
      "Moving malinois pictures.\n",
      "Split 73 imgs into 58 train, 7 val, and 8 test examples.\n",
      "Moving komondor pictures.\n",
      "Split 67 imgs into 53 train, 7 val, and 7 test examples.\n",
      "Moving airedale pictures.\n",
      "Split 107 imgs into 85 train, 11 val, and 11 test examples.\n",
      "Moving leonberg pictures.\n",
      "Split 106 imgs into 84 train, 11 val, and 11 test examples.\n",
      "Moving mexican_hairless pictures.\n",
      "Split 80 imgs into 64 train, 8 val, and 8 test examples.\n",
      "Moving bull_mastiff pictures.\n",
      "Split 75 imgs into 60 train, 7 val, and 8 test examples.\n",
      "Moving bernese_mountain_dog pictures.\n",
      "Split 114 imgs into 91 train, 11 val, and 12 test examples.\n",
      "Moving american_staffordshire_terrier pictures.\n",
      "Split 74 imgs into 59 train, 7 val, and 8 test examples.\n",
      "Moving lhasa pictures.\n",
      "Split 90 imgs into 72 train, 9 val, and 9 test examples.\n",
      "Moving cardigan pictures.\n",
      "Split 76 imgs into 60 train, 8 val, and 8 test examples.\n",
      "Moving italian_greyhound pictures.\n",
      "Split 92 imgs into 73 train, 9 val, and 10 test examples.\n",
      "Moving clumber pictures.\n",
      "Split 80 imgs into 64 train, 8 val, and 8 test examples.\n",
      "Moving scotch_terrier pictures.\n",
      "Split 82 imgs into 65 train, 8 val, and 9 test examples.\n",
      "Moving afghan_hound pictures.\n",
      "Split 116 imgs into 92 train, 12 val, and 12 test examples.\n",
      "Moving old_english_sheepdog pictures.\n",
      "Split 87 imgs into 69 train, 9 val, and 9 test examples.\n",
      "Moving saint_bernard pictures.\n",
      "Split 84 imgs into 67 train, 8 val, and 9 test examples.\n",
      "Moving miniature_pinscher pictures.\n",
      "Split 102 imgs into 81 train, 10 val, and 11 test examples.\n",
      "Moving eskimo_dog pictures.\n",
      "Split 66 imgs into 52 train, 7 val, and 7 test examples.\n",
      "Moving irish_wolfhound pictures.\n",
      "Split 101 imgs into 80 train, 10 val, and 11 test examples.\n",
      "Moving brabancon_griffon pictures.\n",
      "Split 67 imgs into 53 train, 7 val, and 7 test examples.\n",
      "Moving toy_terrier pictures.\n",
      "Split 79 imgs into 63 train, 8 val, and 8 test examples.\n",
      "Moving chow pictures.\n",
      "Split 93 imgs into 74 train, 9 val, and 10 test examples.\n",
      "Moving flat-coated_retriever pictures.\n",
      "Split 72 imgs into 57 train, 7 val, and 8 test examples.\n",
      "Moving norwich_terrier pictures.\n",
      "Split 78 imgs into 62 train, 8 val, and 8 test examples.\n",
      "Moving soft-coated_wheaten_terrier pictures.\n",
      "Split 71 imgs into 56 train, 7 val, and 8 test examples.\n",
      "Moving staffordshire_bullterrier pictures.\n",
      "Split 79 imgs into 63 train, 8 val, and 8 test examples.\n",
      "Moving english_foxhound pictures.\n",
      "Split 86 imgs into 68 train, 9 val, and 9 test examples.\n",
      "Moving gordon_setter pictures.\n",
      "Split 81 imgs into 64 train, 8 val, and 9 test examples.\n",
      "Moving siberian_husky pictures.\n",
      "Split 95 imgs into 76 train, 9 val, and 10 test examples.\n",
      "Moving newfoundland pictures.\n",
      "Split 91 imgs into 72 train, 9 val, and 10 test examples.\n",
      "Moving briard pictures.\n",
      "Split 66 imgs into 52 train, 7 val, and 7 test examples.\n",
      "Moving chesapeake_bay_retriever pictures.\n",
      "Split 83 imgs into 66 train, 8 val, and 9 test examples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving dandie_dinmont pictures.\n",
      "Split 89 imgs into 71 train, 9 val, and 9 test examples.\n",
      "Moving great_pyrenees pictures.\n",
      "Split 111 imgs into 88 train, 11 val, and 12 test examples.\n",
      "Moving beagle pictures.\n",
      "Split 105 imgs into 84 train, 10 val, and 11 test examples.\n",
      "Moving vizsla pictures.\n",
      "Split 70 imgs into 56 train, 7 val, and 7 test examples.\n",
      "Moving west_highland_white_terrier pictures.\n",
      "Split 81 imgs into 64 train, 8 val, and 9 test examples.\n",
      "Moving kerry_blue_terrier pictures.\n",
      "Split 82 imgs into 65 train, 8 val, and 9 test examples.\n",
      "Moving whippet pictures.\n",
      "Split 95 imgs into 76 train, 9 val, and 10 test examples.\n",
      "Moving sealyham_terrier pictures.\n",
      "Split 88 imgs into 70 train, 9 val, and 9 test examples.\n",
      "Moving standard_poodle pictures.\n",
      "Split 79 imgs into 63 train, 8 val, and 8 test examples.\n",
      "Moving keeshond pictures.\n",
      "Split 81 imgs into 64 train, 8 val, and 9 test examples.\n",
      "Moving japanese_spaniel pictures.\n",
      "Split 105 imgs into 84 train, 10 val, and 11 test examples.\n",
      "Moving miniature_poodle pictures.\n",
      "Split 79 imgs into 63 train, 8 val, and 8 test examples.\n",
      "Moving pomeranian pictures.\n",
      "Split 111 imgs into 88 train, 11 val, and 12 test examples.\n",
      "Moving curly-coated_retriever pictures.\n",
      "Split 72 imgs into 57 train, 7 val, and 8 test examples.\n",
      "Moving yorkshire_terrier pictures.\n",
      "Split 82 imgs into 65 train, 8 val, and 9 test examples.\n",
      "Moving pembroke pictures.\n",
      "Split 92 imgs into 73 train, 9 val, and 10 test examples.\n",
      "Moving great_dane pictures.\n",
      "Split 75 imgs into 60 train, 7 val, and 8 test examples.\n",
      "Moving blenheim_spaniel pictures.\n",
      "Split 102 imgs into 81 train, 10 val, and 11 test examples.\n",
      "Moving silky_terrier pictures.\n",
      "Split 90 imgs into 72 train, 9 val, and 9 test examples.\n",
      "Moving sussex_spaniel pictures.\n",
      "Split 78 imgs into 62 train, 8 val, and 8 test examples.\n",
      "Moving german_short-haired_pointer pictures.\n",
      "Split 75 imgs into 60 train, 7 val, and 8 test examples.\n",
      "Moving french_bulldog pictures.\n",
      "Split 70 imgs into 56 train, 7 val, and 7 test examples.\n",
      "Moving bouvier_des_flandres pictures.\n",
      "Split 86 imgs into 68 train, 9 val, and 9 test examples.\n",
      "Moving tibetan_mastiff pictures.\n",
      "Split 69 imgs into 55 train, 7 val, and 7 test examples.\n",
      "Moving english_springer pictures.\n",
      "Split 75 imgs into 60 train, 7 val, and 8 test examples.\n",
      "Moving cocker_spaniel pictures.\n",
      "Split 74 imgs into 59 train, 7 val, and 8 test examples.\n",
      "Moving rottweiler pictures.\n",
      "Split 76 imgs into 60 train, 8 val, and 8 test examples.\n"
     ]
    }
   ],
   "source": [
    "# Check if the folders for 'train' datasets already exists \n",
    "check_for_dir_path= os.path.join(new_root_dir,dir_names[0])\n",
    "\n",
    "if os.path.exists(check_for_dir_path):\n",
    "    create_dirs_copy_data = input(f'The folder{check_for_dir_path} already exists.\\nYou may have previously created the data folders.\\n Delete the old folder and run this cell anyway?(y/n):')    \n",
    "else:\n",
    "    create_dirs_copy_data = 'y'\n",
    "    \n",
    "# Create new sub-directories for each breed inside all dir_names folders\n",
    "if create_dirs_copy_data.lower()=='y':\n",
    "#     list_to_remove = [os.path.join(new_root_dir,file) for file in os.listdir(new_root_dir)]\n",
    "#     [os.remove(x) for x in list_to_remove]\n",
    "#     os.mkdir(new_root_dir)\n",
    "\n",
    "\n",
    "    for d in dir_names:\n",
    "        new_dir = os.path.join(new_root_dir, d)\n",
    "\n",
    "        if os.path.exists(new_dir)==0:\n",
    "            os.mkdir(new_dir)\n",
    "\n",
    "    for breed in df.breed.unique():\n",
    "        print('Moving {} pictures.'.format(breed))\n",
    "        #Create sub_directories\n",
    "        for d in dir_names:\n",
    "            new_dir = os.path.join(new_root_dir, d, breed)\n",
    "            if os.path.exists(new_dir)==0:\n",
    "                os.mkdir(new_dir)\n",
    "\n",
    "        #Subset dataframe into train, validate and split sets\n",
    "        #Split is performed here to ensure maintain class distributions.\n",
    "        temp = df[df.breed == breed]\n",
    "        train, validate, test = np.split(temp.sample(frac=1), [int(.8*len(temp)), int(.9*len(temp))])\n",
    "        print('Split {} imgs into {} train, {} val, and {} test examples.'.format(len(temp),\n",
    "                                                                                  len(train),\n",
    "                                                                                  len(validate),\n",
    "                                                                                  len(test)))\n",
    "        for i, temp in enumerate([train, validate, test]):\n",
    "            for row in temp.index:\n",
    "                filename = temp['id'][row] + '.jpg'\n",
    "                origin = os.path.join(old_dir + filename)\n",
    "                destination = os.path.join(new_root_dir + dir_names[i] + '/' + breed + '/' + filename)\n",
    "                shutil.copy(origin, destination)\n",
    "else:\n",
    "    print('Skipping this cell...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_org/train/ data_org/val/ data_org/test/\n"
     ]
    }
   ],
   "source": [
    "#Your code here; transform the image files and then load them into Keras as tensors \n",
    "#(be sure to perform a train-val-test split)\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img\n",
    "train_dir = new_root_dir+'train/'\n",
    "val_dir = new_root_dir+'val/'\n",
    "test_dir = new_root_dir+'test/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1017 images belonging to 120 classes.\n",
      "Found 8127 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "# train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_dir, \n",
    "        target_size=(240, 240), \n",
    "        batch_size = 20,\n",
    "        class_mode= 'categorical')\n",
    "\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "train_dir, \n",
    "target_size=(240,240),\n",
    "batch_size = 20,\n",
    "class_mode = 'categorical')\n",
    "\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# validation_generator = test_datagen.flow_from_directory(\n",
    "# val_dir, \n",
    "# target_size=(150,150),\n",
    "# batch_size = 20,\n",
    "# class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Build a Baseline CNN\n",
    "\n",
    "This is an optional step. Adapting a pretrained model will produce better results, but it may be interesting to create a CNN from scratch as a baseline. If you wish to, do so here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Create a baseline CNN model\n",
    "# from keras import models, layers, optimizers\n",
    "\n",
    "\n",
    "# model = models.Sequential()\n",
    "\n",
    "# model.add(layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape=(150,150,3)))\n",
    "# model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# model.add(layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# model.add(layers.Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# model.add(layers.Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# num_breeds = len(train_generator.class_indices)\n",
    "# model.add(layers.Flatten())\n",
    "\n",
    "# model.add(layers.Dense(64, activation='relu'))\n",
    "# model.add(layers.Dense(128, activation='relu'))\n",
    "# model.add(layers.Dense(256, activation='relu'))\n",
    "# model.add(layers.Dense(512, activation='relu'))\n",
    "\n",
    "# model.add(layers.Dense(num_breeds, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_58 (Conv2D)           (None, 238, 238, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling (None, 119, 119, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 117, 117, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling (None, 58, 58, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 56, 56, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 26, 26, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 64)                1384512   \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 120)               61560     \n",
      "=================================================================\n",
      "Total params: 1,859,832\n",
      "Trainable params: 1,859,832\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION'S NETWORK\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(240, 240, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(120, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 172s 2s/step - loss: 4.7875 - acc: 0.0075 - val_loss: 4.7874 - val_acc: 0.0080\n",
      "Epoch 2/30\n",
      "  6/100 [>.............................] - ETA: 2:19 - loss: 4.7863 - acc: 0.0083   "
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=30,\n",
    "      validation_data=val_generator,\n",
    "      validation_steps=50)\n",
    "\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "elapsed = end-start\n",
    "print(f'Training the model took {elapsed/60} mins.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# start = datetime.datetime.now()\n",
    "\n",
    "# history = model.fit_generator(train_generator,epochs=30, steps_per_epoch=100,\n",
    "#                               validation_data=validation_generator,validation_steps=50)\n",
    "# end = datetime.datetime.now()\n",
    "# elapsed = end-start\n",
    "# print(f'Training the model took {elapsed/60} mins.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " model.save('CNN_base_model_using_solution.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate_generator(test_generator, steps=54)\n",
    "y_hat_test = model.predict_generator(test_generator, steps=54)\n",
    "\n",
    "print(f'Generated {len(y_hat_test)} predictions')\n",
    "print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRYING OUT LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing out LIME\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os,sys\n",
    "try:\n",
    "    import lime\n",
    "except:\n",
    "    sys.path.append(os.path.join('..', '..')) # add the current directory\n",
    "    import lime\n",
    "from lime import lime_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "%%time\n",
    "# Hide color is the color for a superpixel turned OFF.\n",
    "# Alternatively, if it is NONE, the superpixel will be replaced by the average of its pixels\n",
    "explanation = explainer.explain_instance(images[0],\n",
    "                                         inet_model.predict,\n",
    "                                         top_labels=5,\n",
    "                                         hide_color=0,\n",
    "                                         num_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display only ---identified regions?\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "temp, mask = explanation.get_image_and_mask(295, positive_only=True, num_features=5, hide_rest=True)\n",
    "plt.imshow(mark_boundaries(temp / 2+0.5, mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a Pretrained CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG19\n",
    "conv_base = VGG19(weights='imagenet',include_top=False,input_shape=(150,150,3))\n",
    "conv_base.trainable=False\n",
    "\n",
    "modelP=models.Sequential()\n",
    "modelP.add(conv_base)\n",
    "modelP.add(layers.Flatten())\n",
    "modelP.add(layers.Dense(64, activation='relu'))\n",
    "modelP.add(layers.Dense(128, activation='relu'))\n",
    "modelP.add(layers.Dense(256, activation='relu'))\n",
    "modelP.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "modelP.add(layers.Dense(120, activation='relu'))\n",
    "\n",
    "# Check what layers are trainable\n",
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering with the Pretrained Model\n",
    "\n",
    "Now that you've loaded a pretrained model, it's time to adapt that convolutional base and add some fully connected layers on top in order to build a classifier from these feature maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; add fully connected layers on top of the convolutional base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize History\n",
    "\n",
    "Now fit the model and visualize the training and validation accuracy/loss functions over successive epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; visualize the training / validation history associated with fitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! In this lab, you brought all of your prior deep learning skills together from preprocessing including one-hot encoding, to adapting a pretrained model. There are always ongoing advancements in CNN architectures and best practices, but you have a solid foundation and understanding at this point."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env-ext",
   "language": "python",
   "name": "learn-env-ext"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
